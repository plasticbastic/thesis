\chapter{Additional Chapters}\label{chap:additional_chapters}

If you want, you can add additional chapters to your final report. Keep in mind that the mentioned chapters should at least be present and the main text (excluding title page, table of contents, references and appendices) of the final report should not be more than 15000 words.

Note, if you need more words, please discuss with your supervisor(s).

1. Introduction to Counterfactual Analysis in Recommender Systems
•	Overview of Counterfactual Reasoning: Define counterfactual reasoning and its relevance in AI and recommender systems.
•	Importance in Explainability: Discuss the role of counterfactual analysis in enhancing the explainability of recommender systems.
1.B. XAI in KG Recommender Systems
The Knowledge-aware Path Recurrent Network (KPRN) addresses the challenge of enhancing both accuracy and explainability in recommender systems through the integration of knowledge graphs (KGs). KPRN exploits the rich connectivity information within KGs, using paths of entities and relations to deduce user preferences. It employs a Long Short-Term Memory (LSTM) network to process these paths, capturing the holistic semantics of user-item interactions. A weighted pooling mechanism is applied to prioritize significant paths, enhancing the model's predictive power and transparency. By doing so, KPRN significantly outperforms traditional methods, providing both improved recommendations and clear explanations of the reasoning behind these recommendations in real-world scenarios for movie and music recommendations. (Wang et al., 2019)

In the domain of explainable artificial intelligence (XAI) for knowledge graph (KG) recommender systems, the paper introduces an innovative approach called Path Language Modeling Recommendation (PLM-Rec). This framework leverages a path language model to dynamically predict and extend paths within a KG, allowing the recommendation system to reach previously unreachable items. By incorporating language modeling techniques, PLM-Rec overcomes traditional recall biases in KG-based recommenders, which are limited by the existing KG structure and a fixed number of hops. The technical novelty lies in training a language model on path sequences, akin to sentences in natural language, enabling the generation of new, plausible paths that expand the recommendation scope. This method integrates recommendation generation with explanations, offering transparent and intuitive paths that elucidate why items were recommended. Validated on multiple e-commerce datasets, PLM-Rec demonstrates superior performance in enhancing recommendation accuracy and addressing recall limitations compared to existing methods. (Geng et al., 2022)
This paper addresses the problem of enhancing recommendation accuracy and explanation personalization in recommender systems by integrating structured knowledge bases with collaborative filtering (CF). The proposed neural model leverages knowledge-base embeddings (KBE) to create a unified representation of user behaviors and item properties. It constructs a knowledge graph to encode these relationships and employs a soft matching algorithm for generating personalized explanations. Counterfactuals are generated by exploring different paths within the knowledge graph to determine the impact of various attributes on recommendations. Experimental results on real-world e-commerce datasets demonstrate improved accuracy and explainability, showcasing the model's effectiveness in providing meaningful and personalized recommendations. (Ai et al., 2018)

The paper "Cafe: Coarse-to-Fine Neural Symbolic Reasoning for Explainable Recommendation" addresses the challenge of improving recommendation performance and generating explanations in e-commerce recommender systems by incorporating knowledge graphs (KGs). Knowledge graphs provide rich, structured information about users and items, which can be leveraged to trace paths from users to recommended items, thereby offering explainable recommendations. However, the vast search space, unknown destinations, and sparse signals within the KG pose significant challenges. The Cafe approach tackles these issues with a two-stage process. In the coarse stage, user profiles are generated based on historical data, capturing prominent user behaviors. These profiles act as coarse sketches that guide the subsequent path-finding process. In the fine stage, these user profiles are used to direct a path-finding algorithm called Profile-guided Path Reasoning (PPR). This algorithm employs neural symbolic reasoning modules to efficiently and effectively discover recommendation paths within the KG. User profiles consist of patterns representing user behaviors, extracted from historical activity data. These profiles help focus the path-finding algorithm on relevant paths, improving both the efficiency and effectiveness of the recommendations. The experimental results, conducted on four real-world e-commerce datasets, show substantial improvements in recommendation performance compared to state-of-the-art methods. The paper highlights how integrating user profiles into the recommendation process provides better guidance for path reasoning, resulting in higher quality recommendations. The contributions of this paper include identifying shortcomings in previous KG reasoning approaches, particularly the separation of recommendation and path-finding tasks. Cafe introduces a new paradigm by explicitly incorporating diverse user behaviors into the KG reasoning process. The novel profile-guided path reasoning algorithm, utilizing neural symbolic reasoning modules, is empirically validated, showing significant performance gains across multiple benchmarks. In summary, the Cafe approach enhances e-commerce recommendation systems by integrating user behavior profiles with KG reasoning, enabling more accurate and explainable recommendations through an efficient path-finding process guided by neural symbolic reasoning. (Xian et al., 2020)

The paper addresses the challenge of making Graph Neural Networks (GNNs) explainable in the context of knowledge graphs (KGs). It introduces Monotonic GNNs (MGNNs), a novel class of GNNs that ensure transformations are explainable using logical rules in the Datalog formalism. The approach encodes KGs into graphs with numeric feature vectors, processes these graphs using MGNNs, and decodes the results back into KGs. MGNNs guarantee that transformations are equivalent to applying a set of Datalog rules, allowing for symbolic explanations. This method is applied to KG completion tasks, showing competitive performance while providing clear, logical explanations for predictions. The paper bridges the gap between machine learning and symbolic reasoning, enhancing interpretability in knowledge graph-based tasks. (Tena, et al, 2022)

The paper "Policy-Guided Path Reasoning (PGPR)" introduces a method to enhance the accuracy and explainability of recommendation systems using knowledge graphs (KGs) through explicit reasoning. Unlike traditional methods that primarily use KGs for accuracy, PGPR leverages them to provide interpretable recommendations. The approach employs reinforcement learning (RL), where an agent navigates the KG starting from a user node to find relevant items, offering reasoning paths that enhance interpretability. PGPR introduces innovative strategies such as a soft reward strategy, which designs rewards based on a multi-hop scoring function that accounts for heterogeneous information in the KG, and user-conditional action pruning to handle the large action space in KGs by pruning actions based on their relevance to the user, thereby reducing computational complexity. The policy-guided graph search algorithm efficiently samples reasoning paths during the recommendation process. The method was evaluated on several large-scale real-world datasets from Amazon, demonstrating superior performance compared to state-of-the-art methods using metrics like NDCG, Recall, Hit Rate, and Precision. By providing actual paths in the KG, PGPR makes the reasoning behind recommendations transparent and interpretable, addressing a critical need in modern recommendation systems. Overall, PGPR advances the field by coupling recommendation with interpretability, allowing users to understand the reasoning behind the system's suggestions. (Xian et al., 2019)

2. Counterfactual Methods in Different Types of Recommender Systems
•	Graph-based Recommender Systems: Focus on works like "Causal Inference for Knowledge Graph based Recommendation", highlighting how graph structures facilitate counterfactual reasoning.
•	Neural Recommender Systems: Explore studies such as "Counterfactual Explanations for Neural Recommenders", detailing methods specific to neural networks.
Counterfactual reasoning has been employed in recommender systems, serving a variety of purposes including bias reduction and enhancing explainability. By simulating conditions where certain variables are altered, counterfactual reasoning helps illuminate how such changes could affect outcomes, thereby offering insights into the underlying mechanics of recommender systems. This capability is crucial not only for refining system accuracy but also for ensuring the fairness and transparency of the recommendations provided.
In their study, Wei et al. (2023) introduce the KGCR model, an innovative approach designed to counteract bias in graph-based recommender systems by embedding causal inference within knowledge graph structures. This model enhances the accuracy of reflecting true user preferences through the use of Graph Convolutional Networks (GCNs) to refine the embeddings of users, items, and attributes. These enriched embeddings allow for more contextually informed representations. To mitigate biases, especially those originating from prior user interactions with specific attributes, the KGCR model constructs a causal graph. Interventions using do-calculus are applied to 'cut' edges representing biased influences, thereby creating counterfactual scenarios where such biases are excluded. This adjustment enables the recalibration of similarity scores, assessing potential outcomes had the user not engaged with the biasing attributes.

Further advancing the field, Tran et al. (2021) developed the ACCENT framework, aimed at generating actionable and transparent counterfactual explanations within neural recommender systems. This framework emphasizes the influence of user-item interactions on recommendation outputs. By employing extended influence functions, the ACCENT framework assesses item pairs to understand how modifications in these interactions could alter model predictions. It utilizes Fast Influence Analysis (FIA) to efficiently compute the impact of individual data points, significantly reducing the computational demands typical of large neural networks. This process facilitates the identification of the minimal set of user actions that, if altered, could change the recommendation outcomes, implemented across both Neural Collaborative Filtering (NCF) and Relational Collaborative Filtering (RCF) systems.

This paper addresses the challenge of selection bias in recommender systems by implementing counterfactual policy learning to enhance recommendation fairness and effectiveness. It utilizes Inverse Propensity Scoring (IPS) to generate counterfactuals, weighting observed interactions by the inverse of their occurrence probability under a historical policy. This process allows the model to simulate potential outcomes under alternative recommendation policies. The system employs a two-tower neural model, which effectively separates and processes user and item features, optimizing the recommendation policy through decomposition and adaptive techniques. Counterfactuals are integrated into the learning process by using these weighted outcomes to adjust and refine the policy, ensuring more accurate and equitable recommendations across diverse item spaces and user preferences. This innovative approach tackles inherent biases and operational inefficiencies in traditional recommender systems, leading to improved performance and user satisfaction. (Liu et al., 2022)

The paper introduces "Prince," a method designed to enhance trust and understanding in recommendation systems by providing explanations based on counterfactual reasoning within heterogeneous information networks (HINs). Prince tackles the problem of opaque recommendation processes by identifying minimal sets of user actions (like purchases or ratings) whose absence would lead to different recommendations. It employs Personalized PageRank (PPR) to determine the influence of these actions within the network. The generation of counterfactuals involves a polynomial-time algorithm that efficiently identifies the smallest set of impactful actions, avoiding exhaustive computation. The method's effectiveness is validated through experiments with Amazon and Goodreads datasets, where it outperforms heuristic approaches. Notably, the paper does not utilize a neural model but focuses on a counterfactual approach grounded in network analysis and PPR. (Ghazimatin et al., 2020)

The paper presents the "Counterfactual Explainable Recommendation" (CountER) model, which tackles the challenge of enhancing the explainability of recommendation systems using counterfactual reasoning. CountER identifies the minimal attribute changes needed to alter a recommendation decision, offering clearer insights into the decision-making process. Counterfactuals are generated through a structured optimization problem, where a learning algorithm iteratively adjusts item attributes to find minimal yet impactful changes. These counterfactual scenarios are integrated into the model’s evaluation, employing new metrics to assess the necessity and sufficiency of attribute changes in reversing decisions. The paper validates CountER's effectiveness with extensive experiments across multiple datasets, demonstrating its ability to provide more precise and actionable explanations than existing methods. (Tan et al., 2021)
