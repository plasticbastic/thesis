
@incollection{watson_good_2020,
	location = {Cham},
	title = {Good Counterfactuals and Where to Find Them: A Case-Based Technique for Generating Counterfactuals for Explainable {AI} ({XAI})},
	volume = {12311},
	isbn = {978-3-030-58341-5 978-3-030-58342-2},
	url = {http://link.springer.com/10.1007/978-3-030-58342-2_11},
	shorttitle = {Good Counterfactuals and Where to Find Them},
	abstract = {Recently, a groundswell of research has identified the use of counterfactual explanations as a potentially significant solution to the Explainable {AI} ({XAI}) problem. It is argued that (i) technically, these counterfactual cases can be generated by permuting problem-features until a class-change is found, (ii) psychologically, they are much more causally informative than factual explanations, (iii) legally, they are {GDPR}-compliant. However, there are issues around the finding of “good” counterfactuals using current techniques (e.g. sparsity and plausibility). We show that many commonly-used datasets appear to have few “good” counterfactuals for explanation purposes. We propose a new case-based approach for generating counterfactuals, using novel ideas about the counterfactual potential and explanatory coverage of a case-base. The new technique reuses patterns of good counterfactuals, present in a case-base, to generate analogous counterfactuals that can explain new problems and their solutions. Several experiments show how this technique can improve the counterfactual potential and explanatory coverage of case-bases, that were previously found wanting.},
	pages = {163--178},
	booktitle = {Case-Based Reasoning Research and Development},
	publisher = {Springer International Publishing},
	author = {Keane, Mark T. and Smyth, Barry},
	editor = {Watson, Ian and Weber, Rosina},
	urldate = {2023-12-11},
	date = {2020},
	langid = {english},
	doi = {10.1007/978-3-030-58342-2_11},
	note = {Series Title: Lecture Notes in Computer Science},
	file = {Keane and Smyth - 2020 - Good Counterfactuals and Where to Find Them A Cas.pdf:C\:\\Users\\Celine\\Zotero\\storage\\E5WVAHHF\\Keane and Smyth - 2020 - Good Counterfactuals and Where to Find Them A Cas.pdf:application/pdf},
}

@article{akula_cocox_2020,
	title = {{CoCoX}: Generating Conceptual and Counterfactual Explanations via Fault-Lines},
	volume = {34},
	issn = {2374-3468, 2159-5399},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/5643},
	doi = {10.1609/aaai.v34i03.5643},
	shorttitle = {{CoCoX}},
	abstract = {We present {CoCoX} (short for Conceptual and Counterfactual Explanations), a model for explaining decisions made by a deep convolutional neural network ({CNN}). In Cognitive Psychology, the factors (or semantic-level features) that humans zoom in on when they imagine an alternative to a model prediction are often referred to as fault-lines. Motivated by this, our {CoCoX} model explains decisions made by a {CNN} using fault-lines. Specifically, given an input image I for which a {CNN} classification model M predicts class cpred, our fault-line based explanation identifies the minimal semantic-level features (e.g., stripes on zebra, pointed ears of dog), referred to as explainable concepts, that need to be added to or deleted from I in order to alter the classification category of I by M to another specified class calt. We argue that, due to the conceptual and counterfactual nature of fault-lines, our {CoCoX} explanations are practical and more natural for both expert and non-expert users to understand the internal workings of complex deep learning models. Extensive quantitative and qualitative experiments verify our hypotheses, showing that {CoCoX} significantly outperforms the state-of-the-art explainable {AI} models. Our implementation is available at https://github.com/arjunakula/{CoCoX}},
	pages = {2594--2601},
	number = {3},
	journaltitle = {Proceedings of the {AAAI} Conference on Artificial Intelligence},
	shortjournal = {{AAAI}},
	author = {Akula, Arjun and Wang, Shuai and Zhu, Song-Chun},
	urldate = {2023-12-11},
	date = {2020-04-03},
	file = {Full Text:C\:\\Users\\Celine\\Zotero\\storage\\CV2V2A2P\\Akula et al. - 2020 - CoCoX Generating Conceptual and Counterfactual Ex.pdf:application/pdf},
}

@inproceedings{balloccu_post_2022,
	location = {Madrid Spain},
	title = {Post Processing Recommender Systems with Knowledge Graphs for Recency, Popularity, and Diversity of Explanations},
	isbn = {978-1-4503-8732-3},
	url = {https://dl.acm.org/doi/10.1145/3477495.3532041},
	doi = {10.1145/3477495.3532041},
	eventtitle = {{SIGIR} '22: The 45th International {ACM} {SIGIR} Conference on Research and Development in Information Retrieval},
	pages = {646--656},
	booktitle = {Proceedings of the 45th International {ACM} {SIGIR} Conference on Research and Development in Information Retrieval},
	publisher = {{ACM}},
	author = {Balloccu, Giacomo and Boratto, Ludovico and Fenu, Gianni and Marras, Mirko},
	urldate = {2023-12-12},
	date = {2022-07-06},
	langid = {english},
	file = {Submitted Version:C\:\\Users\\Celine\\Zotero\\storage\\5WC4GK63\\Balloccu et al. - 2022 - Post Processing Recommender Systems with Knowledge.pdf:application/pdf},
}

@article{xu_adversarial_2020,
	title = {Adversarial Counterfactual Learning and Evaluation for Recommender System},
	rights = {{arXiv}.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/2012.02295},
	doi = {10.48550/ARXIV.2012.02295},
	abstract = {The feedback data of recommender systems are often subject to what was exposed to the users; however, most learning and evaluation methods do not account for the underlying exposure mechanism. We first show in theory that applying supervised learning to detect user preferences may end up with inconsistent results in the absence of exposure information. The counterfactual propensity-weighting approach from causal inference can account for the exposure mechanism; nevertheless, the partial-observation nature of the feedback data can cause identifiability issues. We propose a principled solution by introducing a minimax empirical risk formulation. We show that the relaxation of the dual problem can be converted to an adversarial game between two recommendation models, where the opponent of the candidate model characterizes the underlying exposure mechanism. We provide learning bounds and conduct extensive simulation studies to illustrate and justify the proposed approach over a broad range of recommendation settings, which shed insights on the various benefits of the proposed approach.},
	author = {Xu, Da and Ruan, Chuanwei and Korpeoglu, Evren and Kumar, Sushant and Achan, Kannan},
	urldate = {2023-12-12},
	date = {2020},
	note = {Publisher: {arXiv}
Version Number: 1},
	keywords = {{FOS}: Computer and information sciences, Information Retrieval (cs.{IR}), Machine Learning (cs.{LG}), Machine Learning (stat.{ML})},
}

@inproceedings{xian_cafe_2020,
	location = {Virtual Event Ireland},
	title = {{CAFE}: Coarse-to-Fine Neural Symbolic Reasoning for Explainable Recommendation},
	isbn = {978-1-4503-6859-9},
	url = {https://dl.acm.org/doi/10.1145/3340531.3412038},
	doi = {10.1145/3340531.3412038},
	shorttitle = {{CAFE}},
	eventtitle = {{CIKM} '20: The 29th {ACM} International Conference on Information and Knowledge Management},
	pages = {1645--1654},
	booktitle = {Proceedings of the 29th {ACM} International Conference on Information \& Knowledge Management},
	publisher = {{ACM}},
	author = {Xian, Yikun and Fu, Zuohui and Zhao, Handong and Ge, Yingqiang and Chen, Xu and Huang, Qiaoying and Geng, Shijie and Qin, Zhou and De Melo, Gerard and Muthukrishnan, S. and Zhang, Yongfeng},
	urldate = {2023-12-17},
	date = {2020-10-19},
	langid = {english},
	file = {Submitted Version:C\:\\Users\\Celine\\Zotero\\storage\\2BMXT2LQ\\Xian et al. - 2020 - CAFE Coarse-to-Fine Neural Symbolic Reasoning for.pdf:application/pdf},
}

@article{jaimini_causalkg_2022,
	title = {{CausalKG}: Causal Knowledge Graph Explainability Using Interventional and Counterfactual Reasoning},
	volume = {26},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
	issn = {1089-7801, 1941-0131},
	url = {https://ieeexplore.ieee.org/document/9706608/},
	doi = {10.1109/MIC.2021.3133551},
	shorttitle = {{CausalKG}},
	pages = {43--50},
	number = {1},
	journaltitle = {{IEEE} Internet Computing},
	shortjournal = {{IEEE} Internet Comput.},
	author = {Jaimini, Utkarshani and Sheth, Amit},
	urldate = {2024-04-15},
	date = {2022-01-01},
	file = {Submitted Version:C\:\\Users\\Celine\\Zotero\\storage\\7VYGAGH2\\Jaimini and Sheth - 2022 - CausalKG Causal Knowledge Graph Explainability Us.pdf:application/pdf},
}

@article{zellinger_counterfactual_2024,
	title = {Counterfactual Reasoning with Knowledge Graph Embeddings},
	rights = {Creative Commons Attribution 4.0 International},
	url = {https://arxiv.org/abs/2403.06936},
	doi = {10.48550/ARXIV.2403.06936},
	abstract = {Knowledge graph embeddings ({KGEs}) were originally developed to infer true but missing facts in incomplete knowledge repositories. In this paper, we link knowledge graph completion and counterfactual reasoning via our new task {CFKGR}. We model the original world state as a knowledge graph, hypothetical scenarios as edges added to the graph, and plausible changes to the graph as inferences from logical rules. We create corresponding benchmark datasets, which contain diverse hypothetical scenarios with plausible changes to the original knowledge graph and facts that should be retained. We develop {COULDD}, a general method for adapting existing knowledge graph embeddings given a hypothetical premise, and evaluate it on our benchmark. Our results indicate that {KGEs} learn patterns in the graph without explicit training. We further observe that {KGEs} adapted with {COULDD} solidly detect plausible counterfactual changes to the graph that follow these patterns. An evaluation on human-annotated data reveals that {KGEs} adapted with {COULDD} are mostly unable to recognize changes to the graph that do not follow learned inference rules. In contrast, {ChatGPT} mostly outperforms {KGEs} in detecting plausible changes to the graph but has poor knowledge retention. In summary, {CFKGR} connects two previously distinct areas, namely {KG} completion and counterfactual reasoning.},
	author = {Zellinger, Lena and Stephan, Andreas and Roth, Benjamin},
	urldate = {2024-04-15},
	date = {2024},
	note = {Publisher: [object Object]
Version Number: 1},
	keywords = {{FOS}: Computer and information sciences, Artificial Intelligence (cs.{AI}), Computation and Language (cs.{CL}), Machine Learning (cs.{LG})},
	file = {Full Text:C\:\\Users\\Celine\\Zotero\\storage\\YD4NR66Y\\Zellinger et al. - 2024 - Counterfactual Reasoning with Knowledge Graph Embe.pdf:application/pdf},
}

@article{chiappa_path-specific_2019,
	title = {Path-Specific Counterfactual Fairness},
	volume = {33},
	rights = {https://www.aaai.org},
	issn = {2374-3468, 2159-5399},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/4777},
	doi = {10.1609/aaai.v33i01.33017801},
	abstract = {We consider the problem of learning fair decision systems from data in which a sensitive attribute might affect the decision along both fair and unfair pathways. We introduce a counterfactual approach to disregard effects along unfair pathways that does not incur in the same loss of individual-specific information as previous approaches. Our method corrects observations adversely affected by the sensitive attribute, and uses these to form a decision. We leverage recent developments in deep learning and approximate inference to develop a {VAE}-type method that is widely applicable to complex nonlinear models.},
	pages = {7801--7808},
	number = {1},
	journaltitle = {Proceedings of the {AAAI} Conference on Artificial Intelligence},
	shortjournal = {{AAAI}},
	author = {Chiappa, Silvia},
	urldate = {2024-04-16},
	date = {2019-07-17},
	file = {Full Text:C\:\\Users\\Celine\\Zotero\\storage\\3BQAMRUZ\\Chiappa - 2019 - Path-Specific Counterfactual Fairness.pdf:application/pdf},
}

@inproceedings{liu_practical_2022,
	location = {Washington {DC} {USA}},
	title = {Practical Counterfactual Policy Learning for Top-K Recommendations},
	isbn = {978-1-4503-9385-0},
	url = {https://dl.acm.org/doi/10.1145/3534678.3539295},
	doi = {10.1145/3534678.3539295},
	eventtitle = {{KDD} '22: The 28th {ACM} {SIGKDD} Conference on Knowledge Discovery and Data Mining},
	pages = {1141--1151},
	booktitle = {Proceedings of the 28th {ACM} {SIGKDD} Conference on Knowledge Discovery and Data Mining},
	publisher = {{ACM}},
	author = {Liu, Yaxu and Yen, Jui-Nan and Yuan, Bowen and Shi, Rundong and Yan, Peng and Lin, Chih-Jen},
	urldate = {2024-04-16},
	date = {2022-08-14},
	langid = {english},
	file = {Liu et al. - 2022 - Practical Counterfactual Policy Learning for Top-K.pdf:C\:\\Users\\Celine\\Zotero\\storage\\XH43KA7J\\Liu et al. - 2022 - Practical Counterfactual Policy Learning for Top-K.pdf:application/pdf},
}

@inproceedings{tan_counterfactual_2021,
	location = {Virtual Event Queensland Australia},
	title = {Counterfactual Explainable Recommendation},
	isbn = {978-1-4503-8446-9},
	url = {https://dl.acm.org/doi/10.1145/3459637.3482420},
	doi = {10.1145/3459637.3482420},
	eventtitle = {{CIKM} '21: The 30th {ACM} International Conference on Information and Knowledge Management},
	pages = {1784--1793},
	booktitle = {Proceedings of the 30th {ACM} International Conference on Information \& Knowledge Management},
	publisher = {{ACM}},
	author = {Tan, Juntao and Xu, Shuyuan and Ge, Yingqiang and Li, Yunqi and Chen, Xu and Zhang, Yongfeng},
	urldate = {2024-04-16},
	date = {2021-10-26},
	langid = {english},
	file = {Submitted Version:C\:\\Users\\Celine\\Zotero\\storage\\4B33ZZHV\\Tan et al. - 2021 - Counterfactual Explainable Recommendation.pdf:application/pdf},
}

@article{yang_top-n_2021,
	title = {Top-N Recommendation with Counterfactual User Preference Simulation},
	rights = {{arXiv}.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/2109.02444},
	doi = {10.48550/ARXIV.2109.02444},
	abstract = {Top-N recommendation, which aims to learn user ranking-based preference, has long been a fundamental problem in a wide range of applications. Traditional models usually motivate themselves by designing complex or tailored architectures based on different assumptions. However, the training data of recommender system can be extremely sparse and imbalanced, which poses great challenges for boosting the recommendation performance. To alleviate this problem, in this paper, we propose to reformulate the recommendation task within the causal inference framework, which enables us to counterfactually simulate user ranking-based preferences to handle the data scarce problem. The core of our model lies in the counterfactual question: "what would be the user's decision if the recommended items had been different?". To answer this question, we firstly formulate the recommendation process with a series of structural equation models ({SEMs}), whose parameters are optimized based on the observed data. Then, we actively indicate many recommendation lists (called intervention in the causal inference terminology) which are not recorded in the dataset, and simulate user feedback according to the learned {SEMs} for generating new training samples. Instead of randomly intervening on the recommendation list, we design a learning-based method to discover more informative training samples. Considering that the learned {SEMs} can be not perfect, we, at last, theoretically analyze the relation between the number of generated samples and the model prediction error, based on which a heuristic method is designed to control the negative effect brought by the prediction error. Extensive experiments are conducted based on both synthetic and real-world datasets to demonstrate the effectiveness of our framework.},
	author = {Yang, Mengyue and Dai, Quanyu and Dong, Zhenhua and Chen, Xu and He, Xiuqiang and Wang, Jun},
	urldate = {2024-04-16},
	date = {2021},
	note = {Publisher: [object Object]
Version Number: 2},
	keywords = {{FOS}: Computer and information sciences, Information Retrieval (cs.{IR}), Artificial Intelligence (cs.{AI})},
	file = {Full Text:C\:\\Users\\Celine\\Zotero\\storage\\YFDFGTL7\\Yang et al. - 2021 - Top-N Recommendation with Counterfactual User Pref.pdf:application/pdf},
}

@inproceedings{wei_model-agnostic_2021,
	location = {Virtual Event Singapore},
	title = {Model-Agnostic Counterfactual Reasoning for Eliminating Popularity Bias in Recommender System},
	isbn = {978-1-4503-8332-5},
	url = {https://dl.acm.org/doi/10.1145/3447548.3467289},
	doi = {10.1145/3447548.3467289},
	eventtitle = {{KDD} '21: The 27th {ACM} {SIGKDD} Conference on Knowledge Discovery and Data Mining},
	pages = {1791--1800},
	booktitle = {Proceedings of the 27th {ACM} {SIGKDD} Conference on Knowledge Discovery \& Data Mining},
	publisher = {{ACM}},
	author = {Wei, Tianxin and Feng, Fuli and Chen, Jiawei and Wu, Ziwei and Yi, Jinfeng and He, Xiangnan},
	urldate = {2024-04-16},
	date = {2021-08-14},
	langid = {english},
	file = {Submitted Version:C\:\\Users\\Celine\\Zotero\\storage\\NL6UHIYH\\Wei et al. - 2021 - Model-Agnostic Counterfactual Reasoning for Elimin.pdf:application/pdf},
}

@inproceedings{ghazimatin_prince_2020,
	location = {Houston {TX} {USA}},
	title = {{PRINCE}: Provider-side Interpretability with Counterfactual Explanations in Recommender Systems},
	isbn = {978-1-4503-6822-3},
	url = {https://dl.acm.org/doi/10.1145/3336191.3371824},
	doi = {10.1145/3336191.3371824},
	shorttitle = {{PRINCE}},
	eventtitle = {{WSDM} '20: The Thirteenth {ACM} International Conference on Web Search and Data Mining},
	pages = {196--204},
	booktitle = {Proceedings of the 13th International Conference on Web Search and Data Mining},
	publisher = {{ACM}},
	author = {Ghazimatin, Azin and Balalau, Oana and Saha Roy, Rishiraj and Weikum, Gerhard},
	urldate = {2024-04-16},
	date = {2020-01-20},
	langid = {english},
	file = {Full Text:C\:\\Users\\Celine\\Zotero\\storage\\ZNU5FLZZ\\Ghazimatin et al. - 2020 - PRINCE Provider-side Interpretability with Counte.pdf:application/pdf},
}

@inproceedings{chen_dark_2023,
	location = {Taipei Taiwan},
	title = {The Dark Side of Explanations: Poisoning Recommender Systems with Counterfactual Examples},
	isbn = {978-1-4503-9408-6},
	url = {https://dl.acm.org/doi/10.1145/3539618.3592070},
	doi = {10.1145/3539618.3592070},
	shorttitle = {The Dark Side of Explanations},
	eventtitle = {{SIGIR} '23: The 46th International {ACM} {SIGIR} Conference on Research and Development in Information Retrieval},
	pages = {2426--2430},
	booktitle = {Proceedings of the 46th International {ACM} {SIGIR} Conference on Research and Development in Information Retrieval},
	publisher = {{ACM}},
	author = {Chen, Ziheng and Silvestri, Fabrizio and Wang, Jia and Zhang, Yongfeng and Tolomei, Gabriele},
	urldate = {2024-04-17},
	date = {2023-07-19},
	langid = {english},
	file = {Submitted Version:C\:\\Users\\Celine\\Zotero\\storage\\NENJBSSI\\Chen et al. - 2023 - The Dark Side of Explanations Poisoning Recommend.pdf:application/pdf},
}

@inproceedings{tran_counterfactual_2021,
	location = {Virtual Event Canada},
	title = {Counterfactual Explanations for Neural Recommenders},
	isbn = {978-1-4503-8037-9},
	url = {https://dl.acm.org/doi/10.1145/3404835.3463005},
	doi = {10.1145/3404835.3463005},
	eventtitle = {{SIGIR} '21: The 44th International {ACM} {SIGIR} Conference on Research and Development in Information Retrieval},
	pages = {1627--1631},
	booktitle = {Proceedings of the 44th International {ACM} {SIGIR} Conference on Research and Development in Information Retrieval},
	publisher = {{ACM}},
	author = {Tran, Khanh Hiep and Ghazimatin, Azin and Saha Roy, Rishiraj},
	urldate = {2024-04-17},
	date = {2021-07-11},
	langid = {english},
	file = {Full Text:C\:\\Users\\Celine\\Zotero\\storage\\CDQRSJ7P\\Tran et al. - 2021 - Counterfactual Explanations for Neural Recommender.pdf:application/pdf},
}

@article{wang_incorporating_2021,
	title = {Incorporating prior knowledge from counterfactuals into knowledge graph reasoning},
	volume = {223},
	issn = {09507051},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0950705121002987},
	doi = {10.1016/j.knosys.2021.107035},
	pages = {107035},
	journaltitle = {Knowledge-Based Systems},
	shortjournal = {Knowledge-Based Systems},
	author = {Wang, Zikang and Li, Linjing and Zeng, Daniel and Wu, Xiaofei},
	urldate = {2024-04-17},
	date = {2021-07},
	langid = {english},
	file = {Wang et al. - 2021 - Incorporating prior knowledge from counterfactuals.pdf:C\:\\Users\\Celine\\Zotero\\storage\\WCFXMK6V\\Wang et al. - 2021 - Incorporating prior knowledge from counterfactuals.pdf:application/pdf},
}

@inproceedings{guo_towards_2023,
	location = {Birmingham United Kingdom},
	title = {Towards Fair Graph Neural Networks via Graph Counterfactual},
	isbn = {9798400701245},
	url = {https://dl.acm.org/doi/10.1145/3583780.3615092},
	doi = {10.1145/3583780.3615092},
	eventtitle = {{CIKM} '23: The 32nd {ACM} International Conference on Information and Knowledge Management},
	pages = {669--678},
	booktitle = {Proceedings of the 32nd {ACM} International Conference on Information and Knowledge Management},
	publisher = {{ACM}},
	author = {Guo, Zhimeng and Li, Jialiang and Xiao, Teng and Ma, Yao and Wang, Suhang},
	urldate = {2024-04-17},
	date = {2023-10-21},
	langid = {english},
	file = {Submitted Version:C\:\\Users\\Celine\\Zotero\\storage\\Z8E6ISDA\\Guo et al. - 2023 - Towards Fair Graph Neural Networks via Graph Count.pdf:application/pdf},
}

@inproceedings{tan_learning_2022,
	location = {Virtual Event, Lyon France},
	title = {Learning and Evaluating Graph Neural Network Explanations based on Counterfactual and Factual Reasoning},
	isbn = {978-1-4503-9096-5},
	url = {https://dl.acm.org/doi/10.1145/3485447.3511948},
	doi = {10.1145/3485447.3511948},
	eventtitle = {{WWW} '22: The {ACM} Web Conference 2022},
	pages = {1018--1027},
	booktitle = {Proceedings of the {ACM} Web Conference 2022},
	publisher = {{ACM}},
	author = {Tan, Juntao and Geng, Shijie and Fu, Zuohui and Ge, Yingqiang and Xu, Shuyuan and Li, Yunqi and Zhang, Yongfeng},
	urldate = {2024-04-17},
	date = {2022-04-25},
	langid = {english},
	file = {Submitted Version:C\:\\Users\\Celine\\Zotero\\storage\\HND7QZP4\\Tan et al. - 2022 - Learning and Evaluating Graph Neural Network Expla.pdf:application/pdf},
}

@article{lucic_cf-gnnexplainer_2021,
	title = {{CF}-{GNNExplainer}: Counterfactual Explanations for Graph Neural Networks},
	rights = {{arXiv}.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/2102.03322},
	doi = {10.48550/ARXIV.2102.03322},
	shorttitle = {{CF}-{GNNExplainer}},
	abstract = {Given the increasing promise of graph neural networks ({GNNs}) in real-world applications, several methods have been developed for explaining their predictions. Existing methods for interpreting predictions from {GNNs} have primarily focused on generating subgraphs that are especially relevant for a particular prediction. However, such methods are not counterfactual ({CF}) in nature: given a prediction, we want to understand how the prediction can be changed in order to achieve an alternative outcome. In this work, we propose a method for generating {CF} explanations for {GNNs}: the minimal perturbation to the input (graph) data such that the prediction changes. Using only edge deletions, we find that our method, {CF}-{GNNExplainer}, can generate {CF} explanations for the majority of instances across three widely used datasets for {GNN} explanations, while removing less than 3 edges on average, with at least 94{\textbackslash}\% accuracy. This indicates that {CF}-{GNNExplainer} primarily removes edges that are crucial for the original predictions, resulting in minimal {CF} explanations.},
	author = {Lucic, Ana and ter Hoeve, Maartje and Tolomei, Gabriele and de Rijke, Maarten and Silvestri, Fabrizio},
	urldate = {2024-04-17},
	date = {2021},
	note = {Publisher: [object Object]
Version Number: 4},
	keywords = {{FOS}: Computer and information sciences, Artificial Intelligence (cs.{AI}), Machine Learning (cs.{LG})},
	file = {Full Text:C\:\\Users\\Celine\\Zotero\\storage\\LHWRFQ22\\Lucic et al. - 2021 - CF-GNNExplainer Counterfactual Explanations for G.pdf:application/pdf},
}

@article{ma_clear_2022,
	title = {{CLEAR}: Generative Counterfactual Explanations on Graphs},
	rights = {{arXiv}.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/2210.08443},
	doi = {10.48550/ARXIV.2210.08443},
	shorttitle = {{CLEAR}},
	abstract = {Counterfactual explanations promote explainability in machine learning models by answering the question "how should an input instance be perturbed to obtain a desired predicted label?". The comparison of this instance before and after perturbation can enhance human interpretation. Most existing studies on counterfactual explanations are limited in tabular data or image data. In this work, we study the problem of counterfactual explanation generation on graphs. A few studies have explored counterfactual explanations on graphs, but many challenges of this problem are still not well-addressed: 1) optimizing in the discrete and disorganized space of graphs; 2) generalizing on unseen graphs; and 3) maintaining the causality in the generated counterfactuals without prior knowledge of the causal model. To tackle these challenges, we propose a novel framework {CLEAR} which aims to generate counterfactual explanations on graphs for graph-level prediction models. Specifically, {CLEAR} leverages a graph variational autoencoder based mechanism to facilitate its optimization and generalization, and promotes causality by leveraging an auxiliary variable to better identify the underlying causal model. Extensive experiments on both synthetic and real-world graphs validate the superiority of {CLEAR} over the state-of-the-art methods in different aspects.},
	author = {Ma, Jing and Guo, Ruocheng and Mishra, Saumitra and Zhang, Aidong and Li, Jundong},
	urldate = {2024-04-17},
	date = {2022},
	note = {Publisher: [object Object]
Version Number: 2},
	keywords = {{FOS}: Computer and information sciences, Machine Learning (cs.{LG})},
	file = {Full Text:C\:\\Users\\Celine\\Zotero\\storage\\7XMGYK7W\\Ma et al. - 2022 - CLEAR Generative Counterfactual Explanations on G.pdf:application/pdf},
}

@article{wei_causal_2023,
	title = {Causal Inference for Knowledge Graph Based Recommendation},
	volume = {35},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
	issn = {1041-4347, 1558-2191, 2326-3865},
	url = {https://ieeexplore.ieee.org/document/9996555/},
	doi = {10.1109/TKDE.2022.3231352},
	pages = {11153--11164},
	number = {11},
	journaltitle = {{IEEE} Transactions on Knowledge and Data Engineering},
	shortjournal = {{IEEE} Trans. Knowl. Data Eng.},
	author = {Wei, Yinwei and Wang, Xiang and Nie, Liqiang and Li, Shaoyu and Wang, Dingxian and Chua, Tat-Seng},
	urldate = {2024-04-20},
	date = {2023-11-01},
	file = {Submitted Version:C\:\\Users\\Celine\\Zotero\\storage\\CFTJYLCR\\Wei et al. - 2023 - Causal Inference for Knowledge Graph Based Recomme.pdf:application/pdf},
}

@article{wang_explainable_2019,
	title = {Explainable Reasoning over Knowledge Graphs for Recommendation},
	volume = {33},
	rights = {https://www.aaai.org},
	issn = {2374-3468, 2159-5399},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/4470},
	doi = {10.1609/aaai.v33i01.33015329},
	abstract = {Incorporating knowledge graph into recommender systems has attracted increasing attention in recent years. By exploring the interlinks within a knowledge graph, the connectivity between users and items can be discovered as paths, which provide rich and complementary information to user-item interactions. Such connectivity not only reveals the semantics of entities and relations, but also helps to comprehend a user’s interest. However, existing efforts have not fully explored this connectivity to infer user preferences, especially in terms of modeling the sequential dependencies within and holistic semantics of a path.In this paper, we contribute a new model named Knowledgeaware Path Recurrent Network ({KPRN}) to exploit knowledge graph for recommendation. {KPRN} can generate path representations by composing the semantics of both entities and relations. By leveraging the sequential dependencies within a path, we allow effective reasoning on paths to infer the underlying rationale of a user-item interaction. Furthermore, we design a new weighted pooling operation to discriminate the strengths of different paths in connecting a user with an item, endowing our model with a certain level of explainability. We conduct extensive experiments on two datasets about movie and music, demonstrating significant improvements over state-of-the-art solutions Collaborative Knowledge Base Embedding and Neural Factorization Machine.},
	pages = {5329--5336},
	number = {1},
	journaltitle = {Proceedings of the {AAAI} Conference on Artificial Intelligence},
	shortjournal = {{AAAI}},
	author = {Wang, Xiang and Wang, Dingxian and Xu, Canran and He, Xiangnan and Cao, Yixin and Chua, Tat-Seng},
	urldate = {2024-04-20},
	date = {2019-07-17},
	file = {Full Text:C\:\\Users\\Celine\\Zotero\\storage\\CKCXZV5V\\Wang et al. - 2019 - Explainable Reasoning over Knowledge Graphs for Re.pdf:application/pdf},
}

@article{ai_learning_2018,
	title = {Learning Heterogeneous Knowledge Base Embeddings for Explainable Recommendation},
	volume = {11},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1999-4893},
	url = {http://www.mdpi.com/1999-4893/11/9/137},
	doi = {10.3390/a11090137},
	abstract = {Providing model-generated explanations in recommender systems is important to user experience. State-of-the-art recommendation algorithms—especially the collaborative filtering ({CF})- based approaches with shallow or deep models—usually work with various unstructured information sources for recommendation, such as textual reviews, visual images, and various implicit or explicit feedbacks. Though structured knowledge bases were considered in content-based approaches, they have been largely ignored recently due to the availability of vast amounts of data and the learning power of many complex models. However, structured knowledge bases exhibit unique advantages in personalized recommendation systems. When the explicit knowledge about users and items is considered for recommendation, the system could provide highly customized recommendations based on users’ historical behaviors and the knowledge is helpful for providing informed explanations regarding the recommended items. A great challenge for using knowledge bases for recommendation is how to integrate large-scale structured and unstructured data, while taking advantage of collaborative filtering for highly accurate performance. Recent achievements in knowledge-base embedding ({KBE}) sheds light on this problem, which makes it possible to learn user and item representations while preserving the structure of their relationship with external knowledge for explanation. In this work, we propose to explain knowledge-base embeddings for explainable recommendation. Specifically, we propose a knowledge-base representation learning framework to embed heterogeneous entities for recommendation, and based on the embedded knowledge base, a soft matching algorithm is proposed to generate personalized explanations for the recommended items. Experimental results on real-world e-commerce datasets verified the superior recommendation performance and the explainability power of our approach compared with state-of-the-art baselines.},
	pages = {137},
	number = {9},
	journaltitle = {Algorithms},
	shortjournal = {Algorithms},
	author = {Ai, Qingyao and Azizi, Vahid and Chen, Xu and Zhang, Yongfeng},
	urldate = {2024-04-25},
	date = {2018-09-13},
	langid = {english},
	file = {Full Text:C\:\\Users\\Celine\\Zotero\\storage\\HIFY7I9P\\Ai et al. - 2018 - Learning Heterogeneous Knowledge Base Embeddings f.pdf:application/pdf},
}

@inproceedings{geng_path_2022,
	location = {Virtual Event, Lyon France},
	title = {Path Language Modeling over Knowledge Graphsfor Explainable Recommendation},
	isbn = {978-1-4503-9096-5},
	url = {https://dl.acm.org/doi/10.1145/3485447.3511937},
	doi = {10.1145/3485447.3511937},
	eventtitle = {{WWW} '22: The {ACM} Web Conference 2022},
	pages = {946--955},
	booktitle = {Proceedings of the {ACM} Web Conference 2022},
	publisher = {{ACM}},
	author = {Geng, Shijie and Fu, Zuohui and Tan, Juntao and Ge, Yingqiang and De Melo, Gerard and Zhang, Yongfeng},
	urldate = {2024-05-06},
	date = {2022-04-25},
	langid = {english},
	file = {Full Text:C\:\\Users\\Celine\\Zotero\\storage\\A2R7NW8H\\Geng et al. - 2022 - Path Language Modeling over Knowledge Graphsfor Ex.pdf:application/pdf},
}

@article{medda_gnnuers_2024,
	title = {{GNNUERS}: Fairness Explanation in {GNNs} for Recommendation via Counterfactual Reasoning},
	issn = {2157-6904, 2157-6912},
	url = {https://dl.acm.org/doi/10.1145/3655631},
	doi = {10.1145/3655631},
	shorttitle = {{GNNUERS}},
	abstract = {Nowadays, research into personalization has been focusing on explainability and fairness. Several approaches proposed in recent works are able to explain individual recommendations in a post-hoc manner or by explanation paths. However, explainability techniques applied to unfairness in recommendation have been limited to finding user/item features mostly related to biased recommendations. In this paper, we devised a novel algorithm that leverages counterfactuality methods to discover user unfairness explanations in the form of user-item interactions. In our counterfactual framework, interactions are represented as edges in a bipartite graph, with users and items as nodes. Our bipartite graph explainer perturbs the topological structure to find an altered version that minimizes the disparity in utility between the protected and unprotected demographic groups. Experiments on four real-world graphs coming from various domains showed that our method can systematically explain user unfairness on three state-of-the-art {GNN}-based recommendation models. Moreover, an empirical evaluation of the perturbed network uncovered relevant patterns that justify the nature of the unfairness discovered by the generated explanations. The source code and the preprocessed data sets are available at https://github.com/jackmedda/{RS}-{BGExplainer}.},
	pages = {3655631},
	journaltitle = {{ACM} Transactions on Intelligent Systems and Technology},
	shortjournal = {{ACM} Trans. Intell. Syst. Technol.},
	author = {Medda, Giacomo and Fabbri, Francesco and Marras, Mirko and Boratto, Ludovico and Fenu, Gianni},
	urldate = {2024-05-07},
	date = {2024-04-03},
	langid = {english},
	file = {Full Text:C\:\\Users\\Celine\\Zotero\\storage\\P7ERWIY9\\Medda et al. - 2024 - GNNUERS Fairness Explanation in GNNs for Recommen.pdf:application/pdf},
}

@article{wang_reinforced_2024,
	title = {Reinforced Path Reasoning for Counterfactual Explainable Recommendation},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
	issn = {1041-4347, 1558-2191, 2326-3865},
	url = {https://ieeexplore.ieee.org/document/10399934/},
	doi = {10.1109/TKDE.2024.3354077},
	pages = {1--17},
	journaltitle = {{IEEE} Transactions on Knowledge and Data Engineering},
	shortjournal = {{IEEE} Trans. Knowl. Data Eng.},
	author = {Wang, Xiangmeng and Li, Qian and Yu, Dianer and Li, Qing and Xu, Guandong},
	urldate = {2024-05-07},
	date = {2024},
	file = {Submitted Version:C\:\\Users\\Celine\\Zotero\\storage\\Y4DVTXI2\\Wang et al. - 2024 - Reinforced Path Reasoning for Counterfactual Expla.pdf:application/pdf},
}

@inproceedings{noauthor_explainable_nodate,
	title = {Explainable {GNN}-based models over knowledge graphs},
}

@inproceedings{xian_reinforcement_2019,
	location = {Paris France},
	title = {Reinforcement Knowledge Graph Reasoning for Explainable Recommendation},
	isbn = {978-1-4503-6172-9},
	url = {https://dl.acm.org/doi/10.1145/3331184.3331203},
	doi = {10.1145/3331184.3331203},
	eventtitle = {{SIGIR} '19: The 42nd International {ACM} {SIGIR} Conference on Research and Development in Information Retrieval},
	pages = {285--294},
	booktitle = {Proceedings of the 42nd International {ACM} {SIGIR} Conference on Research and Development in Information Retrieval},
	publisher = {{ACM}},
	author = {Xian, Yikun and Fu, Zuohui and Muthukrishnan, S. and De Melo, Gerard and Zhang, Yongfeng},
	urldate = {2024-05-17},
	date = {2019-07-18},
	langid = {english},
	file = {Submitted Version:C\:\\Users\\Celine\\Zotero\\storage\\56IHWS7C\\Xian et al. - 2019 - Reinforcement Knowledge Graph Reasoning for Explai.pdf:application/pdf},
}

@article{blondel_fast_2008,
	title = {Fast unfolding of communities in large networks},
	volume = {2008},
	issn = {1742-5468},
	url = {https://iopscience.iop.org/article/10.1088/1742-5468/2008/10/P10008},
	doi = {10.1088/1742-5468/2008/10/P10008},
	pages = {P10008},
	number = {10},
	journaltitle = {Journal of Statistical Mechanics: Theory and Experiment},
	shortjournal = {J. Stat. Mech.},
	author = {Blondel, Vincent D and Guillaume, Jean-Loup and Lambiotte, Renaud and Lefebvre, Etienne},
	urldate = {2024-05-18},
	date = {2008-10-09},
	file = {Submitted Version:C\:\\Users\\Celine\\Zotero\\storage\\VVVC8ESR\\Blondel et al. - 2008 - Fast unfolding of communities in large networks.pdf:application/pdf},
}



@article{zhang_explainable_2020,
	title = {Explainable Recommendation: A Survey and New Perspectives},
	volume = {14},
	issn = {1554-0669, 1554-0677},
	url = {http://www.nowpublishers.com/article/Details/INR-066},
	doi = {10.1561/1500000066},
	shorttitle = {Explainable Recommendation},
	pages = {1--101},
	number = {1},
	journaltitle = {Foundations and Trends® in Information Retrieval},
	shortjournal = {{FNT} in Information Retrieval},
	author = {Zhang, Yongfeng and Chen, Xu},
	urldate = {2023-10-12},
	date = {2020},
	langid = {english},
	file = {Submitted Version:C\:\\Users\\Celine\\Zotero\\storage\\BVV6QWEN\\Zhang and Chen - 2020 - Explainable Recommendation A Survey and New Persp.pdf:application/pdf},
}

@inproceedings{byrne_counterfactuals_2019,
	location = {Macao, China},
	title = {Counterfactuals in Explainable Artificial Intelligence ({XAI}): Evidence from Human Reasoning},
	isbn = {978-0-9992411-4-1},
	url = {https://www.ijcai.org/proceedings/2019/876},
	doi = {10.24963/ijcai.2019/876},
	shorttitle = {Counterfactuals in Explainable Artificial Intelligence ({XAI})},
	abstract = {Counterfactuals about what could have happened are increasingly used in an array of Artificial Intelligence ({AI}) applications, and especially in explainable {AI} ({XAI}).  Counterfactuals can aid the provision of interpretable models to make the decisions of inscrutable systems intelligible to developers and users. However, not all counterfactuals are equally helpful in assisting human comprehension. Discoveries about the nature of the counterfactuals that humans create are a helpful guide to maximize the effectiveness of counterfactual use in {AI}.},
	eventtitle = {Twenty-Eighth International Joint Conference on Artificial Intelligence \{{IJCAI}-19\}},
	pages = {6276--6282},
	booktitle = {Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence},
	publisher = {International Joint Conferences on Artificial Intelligence Organization},
	author = {Byrne, Ruth M. J.},
	urldate = {2024-05-07},
	date = {2019-08},
	langid = {english},
	file = {Full Text:C\:\\Users\\Celine\\Zotero\\storage\\CG8ULPSN\\Byrne - 2019 - Counterfactuals in Explainable Artificial Intellig.pdf:application/pdf},
}

@article{jannach_measuring_2019,
	title = {Measuring the Business Value of Recommender Systems},
	volume = {10},
	issn = {2158-656X, 2158-6578},
	url = {https://dl.acm.org/doi/10.1145/3370082},
	doi = {10.1145/3370082},
	abstract = {Recommender Systems are nowadays successfully used by all major web sites—from e-commerce to social media—to filter content and make suggestions in a personalized way. Academic research largely focuses on the value of recommenders for consumers, e.g., in terms of reduced information overload. To what extent and in which ways recommender systems create
              business value
              is, however, much less clear, and the literature on the topic is scattered. In this research commentary, we review existing publications on field tests of recommender systems and report which business-related performance measures were used in such real-world deployments. We summarize common challenges of measuring the business value in practice and critically discuss the value of algorithmic improvements and offline experiments as commonly done in academic environments. Overall, our review indicates that various open questions remain both regarding the realistic quantification of the business effects of recommenders and the performance assessment of recommendation algorithms in academia.},
	pages = {1--23},
	number = {4},
	journaltitle = {{ACM} Transactions on Management Information Systems},
	shortjournal = {{ACM} Trans. Manage. Inf. Syst.},
	author = {Jannach, Dietmar and Jugovac, Michael},
	urldate = {2024-05-19},
	date = {2019-12-31},
	langid = {english},
	file = {Submitted Version:C\:\\Users\\Celine\\Zotero\\storage\\62QULR45\\Jannach and Jugovac - 2019 - Measuring the Business Value of Recommender System.pdf:application/pdf},
}

@book{aggarwal_recommender_2016,
	location = {Cham},
	title = {Recommender Systems},
	rights = {http://www.springer.com/tdm},
	isbn = {978-3-319-29657-9 978-3-319-29659-3},
	url = {http://link.springer.com/10.1007/978-3-319-29659-3},
	publisher = {Springer International Publishing},
	author = {Aggarwal, Charu C.},
	urldate = {2024-05-19},
	date = {2016},
	langid = {english},
	doi = {10.1007/978-3-319-29659-3},
	file = {Full Text:C\:\\Users\\Celine\\Zotero\\storage\\DVSNWABY\\Aggarwal - 2016 - Recommender Systems.pdf:application/pdf},
}

@inproceedings{vultureanu-albisi_recommender_2021,
	location = {Kocaeli, Turkey},
	title = {Recommender Systems: An Explainable {AI} Perspective},
	rights = {https://doi.org/10.15223/policy-029},
	isbn = {978-1-66543-603-8},
	url = {https://ieeexplore.ieee.org/document/9548125/},
	doi = {10.1109/INISTA52262.2021.9548125},
	shorttitle = {Recommender Systems},
	eventtitle = {2021 International Conference on {INnovations} in Intelligent {SysTems} and Applications ({INISTA})},
	pages = {1--6},
	booktitle = {2021 International Conference on {INnovations} in Intelligent {SysTems} and Applications ({INISTA})},
	publisher = {{IEEE}},
	author = {Vultureanu-Albisi, Alexandra and Badica, Costin},
	urldate = {2024-05-19},
	date = {2021-08-25},
}

@article{tiddi_knowledge_2022,
	title = {Knowledge graphs as tools for explainable machine learning: A survey},
	volume = {302},
	issn = {00043702},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0004370221001788},
	doi = {10.1016/j.artint.2021.103627},
	shorttitle = {Knowledge graphs as tools for explainable machine learning},
	pages = {103627},
	journaltitle = {Artificial Intelligence},
	shortjournal = {Artificial Intelligence},
	author = {Tiddi, Ilaria and Schlobach, Stefan},
	urldate = {2024-05-19},
	date = {2022-01},
	langid = {english},
}



@article{guo_survey_2020,
	title = {A Survey on Knowledge Graph-Based Recommender Systems},
	volume = {34},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
	issn = {1041-4347, 1558-2191, 2326-3865},
	url = {https://ieeexplore.ieee.org/document/9216015/},
	doi = {10.1109/TKDE.2020.3028705},
	pages = {3549--3568},
	number = {8},
	journaltitle = {{IEEE} Transactions on Knowledge and Data Engineering},
	shortjournal = {{IEEE} Trans. Knowl. Data Eng.},
	author = {Guo, Qingyu and Zhuang, Fuzhen and Qin, Chuan and Zhu, Hengshu and Xie, Xing and Xiong, Hui and He, Qing},
	urldate = {2024-04-13},
	date = {2020-10-07},
	file = {Full Text:C\:\\Users\\Celine\\Zotero\\storage\\8EVEK4S6\\Guo et al. - 2022 - A Survey on Knowledge Graph-Based Recommender Syst.pdf:application/pdf},
}
